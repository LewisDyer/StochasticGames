# Week 10 Status Report - 25/11/20

This week, I have continued further development of the experiment automation environment. Output from different models is now placed in different folders, so that experiment data from different models can now be compared and contrasted (and crucially, particularly laborious experiments only need to be performed once). In particular, experiments were completed on two particular cases (the 12-board variant with 2 six-sided dice, and the 12-board variant with a single 12-sided die), making initial attempts to compare their graphs. I have also refactored the calculation of conditional probabilities to avoid floating point error, and moreover I also explored different ways to generate strategies for different models and perform comparisons, using the 6-board variant with a single 6-sided die as a small example to visualise.

Overall, I think that I won't be able to do much work around strategy generation in this project (from my initial research, in particular when dealing with large graphs, it seems like a rabbit hole that I could spend far too much time on), and I would prefer to focus on a breadth of examples of different games. That being said, comparing strategies via looking at individual vertices, considering what decisions are made under different strategies, and noting where this difference occurs, seems like a relatively simple technique that could be applicable to my other games too.

# Questions/Comments

* Comparing the graphs of the two 12-board variants gives some interesting differences, in particular where the probabilities in the 2d6 graph appear to peak at triangular numbers. My current intuition is that this occurs in places where "bad" decisions can lead to the game ending prematurely (e.g if you roll a 10 and cover boards 1-4, that limits a lot more options for future rolls than if you cover board 10), but I'm struggling to come up with ideas as to why that doesn't really show in the 1d12 graph.

* On a similar note, after computing and visualising the conditional probabilities for each score given that a particular board is covered, I noticed some peculiar patterns, where a particular shape appears to repeat periodically in the graph (while increasing) - an example for board 4 is shown but it's applicable to every graph to some extent. I'm curious why this could be the case - it does seem to be related to the triangular numbers somehow, but given it's not an exact match there could be some element of coincedence as well

* My current thinking is that it will be more effective for me to move onto Liar's Dice soon, even if Shut the Box isn't completed - I might come up with some ideas for analysis that could later be applied to Shut the Box, and if I spend too long on Shut the Box now there's the risk that my other case studies will be under-developed.

* Are there any ways I can express hidden information in PRISM? Looking ahead to Liar's Dice, I'd like players to be aware of the number of total dice available, but only know the values on their own set of dice (i.e strategies shouldn't be able to factor in information they can't see). I can see how to do this when defining specific strategies using guards, but not for generating optimal strategies.

# Plan for next week

* Start working on strategy comparison by comparing decisions at each vertex. This is similar to a diff, but complicated by the fact that different vertices have different identifiers in each strategy (since they're defined sequentially, and a state may be reachable in one strategy but not another).
* Finish collecting data for ShutTheBox for now, then start thinking about modelling Liar's Dice for the December project period (this week I should focus more on reading about the game, think about interesting properties to consider, and start planning how to model this game for a small example).